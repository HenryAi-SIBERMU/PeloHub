"""
JSON Output Validator for Kaggle Training Notebook
Validates the structure of all JSON files that will be generated by the training notebook.
Run this BEFORE uploading to Kaggle to catch any structural errors early.
"""

import json
import os
import sys
from typing import Dict, List, Any

class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    END = '\033[0m'

def validate_dataset_stats(data: Dict) -> List[str]:
    """Validate dataset_stats.json structure"""
    errors = []
    
    required_datasets = ['uaspeech', 'torgo']
    for ds in required_datasets:
        if ds not in data:
            errors.append(f"Missing dataset: {ds}")
            continue
        
        ds_data = data[ds]
        
        # Check required fields
        if 'name' not in ds_data:
            errors.append(f"{ds}: Missing 'name' field")
        
        if 'stats' not in ds_data:
            errors.append(f"{ds}: Missing 'stats' field")
        else:
            stats = ds_data['stats']
            required_stats = ['samples', 'classes', 'avgLen']
            for stat in required_stats:
                if stat not in stats:
                    errors.append(f"{ds}.stats: Missing '{stat}' field")
        
        if 'summaryData' not in ds_data:
            errors.append(f"{ds}: Missing 'summaryData' field")
        else:
            summary = ds_data['summaryData']
            if not isinstance(summary, list):
                errors.append(f"{ds}.summaryData: Should be a list")
            elif len(summary) > 0:
                # Check first item structure
                item = summary[0]
                required_fields = ['category', 'speakers', 'totalRaw', 'trainRaw', 'testRaw']
                for field in required_fields:
                    if field not in item:
                        errors.append(f"{ds}.summaryData[0]: Missing '{field}' field")
    
    return errors

def validate_benchmark_summary(data: List[Dict]) -> List[str]:
    """Validate benchmark_summary.json structure"""
    errors = []
    
    if not isinstance(data, list):
        return ["benchmark_summary.json should be a list"]
    
    if len(data) == 0:
        return ["benchmark_summary.json is empty"]
    
    required_fields = ['model', 'dataset', 'accuracy', 'inference_time_ms', 'training_time_sec', 'run_name']
    
    for idx, entry in enumerate(data):
        for field in required_fields:
            if field not in entry:
                errors.append(f"Entry {idx}: Missing '{field}' field")
        
        # Type checks
        if 'accuracy' in entry and not isinstance(entry['accuracy'], (int, float)):
            errors.append(f"Entry {idx}: 'accuracy' should be a number")
        
        if 'inference_time_ms' in entry and not isinstance(entry['inference_time_ms'], (int, float)):
            errors.append(f"Entry {idx}: 'inference_time_ms' should be a number")
    
    return errors

def validate_model_efficiency(data: Dict) -> List[str]:
    """Validate model_efficiency.json structure"""
    errors = []
    
    if not isinstance(data, dict):
        return ["model_efficiency.json should be a dictionary"]
    
    if len(data) == 0:
        return ["model_efficiency.json is empty"]
    
    required_fields = ['params', 'flops', 'size', 'activation']
    
    for model_name, metrics in data.items():
        if not isinstance(metrics, dict):
            errors.append(f"{model_name}: Should be a dictionary")
            continue
        
        for field in required_fields:
            if field not in metrics:
                errors.append(f"{model_name}: Missing '{field}' field")
    
    return errors

def validate_eval_json(data: Dict, filename: str) -> List[str]:
    """Validate *_eval.json structure (CM, ROC, PR curves)"""
    errors = []
    
    required_fields = ['cm', 'roc', 'pr', 'auroc']
    
    for field in required_fields:
        if field not in data:
            errors.append(f"{filename}: Missing '{field}' field")
    
    # Validate confusion matrix
    if 'cm' in data:
        cm = data['cm']
        if not isinstance(cm, list):
            errors.append(f"{filename}.cm: Should be a list")
        elif len(cm) != 2:
            errors.append(f"{filename}.cm: Should have 2 rows (binary classification)")
        else:
            for i, row in enumerate(cm):
                if not isinstance(row, list) or len(row) != 2:
                    errors.append(f"{filename}.cm[{i}]: Should be a list of 2 elements")
    
    # Validate ROC curve
    if 'roc' in data:
        roc = data['roc']
        if not isinstance(roc, list):
            errors.append(f"{filename}.roc: Should be a list")
        elif len(roc) > 0:
            point = roc[0]
            if not isinstance(point, dict) or 'x' not in point or 'y' not in point:
                errors.append(f"{filename}.roc[0]: Should have 'x' and 'y' fields")
    
    # Validate PR curve
    if 'pr' in data:
        pr = data['pr']
        if not isinstance(pr, list):
            errors.append(f"{filename}.pr: Should be a list")
        elif len(pr) > 0:
            point = pr[0]
            if not isinstance(point, dict) or 'x' not in point or 'y' not in point:
                errors.append(f"{filename}.pr[0]: Should have 'x' and 'y' fields")
    
    # Validate AUROC
    if 'auroc' in data:
        if not isinstance(data['auroc'], (int, float)):
            errors.append(f"{filename}.auroc: Should be a number")
    
    return errors

def validate_report_json(data: Dict, filename: str) -> List[str]:
    """Validate *_report.json structure (classification report)"""
    errors = []
    
    # Should have 'accuracy' at top level
    if 'accuracy' not in data:
        errors.append(f"{filename}: Missing 'accuracy' field")
    
    # Should have class-level metrics
    required_metrics = ['precision', 'recall', 'f1-score', 'support']
    
    # Check for at least one class entry (could be '0', '1', or class names)
    has_class_metrics = False
    for key, value in data.items():
        if isinstance(value, dict) and 'precision' in value:
            has_class_metrics = True
            # Validate this class entry
            for metric in required_metrics:
                if metric not in value:
                    errors.append(f"{filename}.{key}: Missing '{metric}' field")
    
    if not has_class_metrics:
        errors.append(f"{filename}: No class-level metrics found")
    
    return errors

def main():
    print(f"\n{Colors.BLUE}{'='*60}{Colors.END}")
    print(f"{Colors.BLUE}JSON Output Validator for Kaggle Training Notebook{Colors.END}")
    print(f"{Colors.BLUE}{'='*60}{Colors.END}\n")
    
    # Define expected JSON files
    outputs_dir = "backend/outputs"
    
    validators = {
        "dataset_stats.json": validate_dataset_stats,
        "benchmark_summary.json": validate_benchmark_summary,
        "model_efficiency.json": validate_model_efficiency,
    }
    
    total_errors = 0
    total_warnings = 0
    
    # Validate each file
    for filename, validator in validators.items():
        filepath = os.path.join(outputs_dir, filename)
        print(f"üìÑ Validating: {filename}")
        
        if not os.path.exists(filepath):
            print(f"   {Colors.YELLOW}‚ö†Ô∏è  File not found (will be generated by Kaggle){Colors.END}")
            total_warnings += 1
            continue
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            errors = validator(data)
            
            if errors:
                print(f"   {Colors.RED}‚ùå Found {len(errors)} error(s):{Colors.END}")
                for error in errors:
                    print(f"      ‚Ä¢ {error}")
                total_errors += len(errors)
            else:
                print(f"   {Colors.GREEN}‚úÖ Valid{Colors.END}")
        
        except json.JSONDecodeError as e:
            print(f"   {Colors.RED}‚ùå JSON Parse Error: {e}{Colors.END}")
            total_errors += 1
        except Exception as e:
            print(f"   {Colors.RED}‚ùå Error: {e}{Colors.END}")
            total_errors += 1
    
    # Check for eval and report JSONs
    print(f"\nüìÑ Checking for evaluation JSONs (*_eval.json, *_report.json)")
    eval_files = [f for f in os.listdir(outputs_dir) if f.endswith('_eval.json')]
    report_files = [f for f in os.listdir(outputs_dir) if f.endswith('_report.json')]
    
    if not eval_files:
        print(f"   {Colors.YELLOW}‚ö†Ô∏è  No *_eval.json files found (will be generated by Kaggle){Colors.END}")
        total_warnings += 1
    else:
        for filename in eval_files:
            filepath = os.path.join(outputs_dir, filename)
            print(f"   Validating: {filename}")
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                errors = validate_eval_json(data, filename)
                if errors:
                    print(f"      {Colors.RED}‚ùå Found {len(errors)} error(s):{Colors.END}")
                    for error in errors:
                        print(f"         ‚Ä¢ {error}")
                    total_errors += len(errors)
                else:
                    print(f"      {Colors.GREEN}‚úÖ Valid{Colors.END}")
            except Exception as e:
                print(f"      {Colors.RED}‚ùå Error: {e}{Colors.END}")
                total_errors += 1
    
    if not report_files:
        print(f"   {Colors.YELLOW}‚ö†Ô∏è  No *_report.json files found (will be generated by Kaggle){Colors.END}")
        total_warnings += 1
    else:
        for filename in report_files:
            filepath = os.path.join(outputs_dir, filename)
            print(f"   Validating: {filename}")
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                errors = validate_report_json(data, filename)
                if errors:
                    print(f"      {Colors.RED}‚ùå Found {len(errors)} error(s):{Colors.END}")
                    for error in errors:
                        print(f"         ‚Ä¢ {error}")
                    total_errors += len(errors)
                else:
                    print(f"      {Colors.GREEN}‚úÖ Valid{Colors.END}")
            except Exception as e:
                print(f"      {Colors.RED}‚ùå Error: {e}{Colors.END}")
                total_errors += 1
    
    # Summary
    print(f"\n{Colors.BLUE}{'='*60}{Colors.END}")
    print(f"{Colors.BLUE}Validation Summary{Colors.END}")
    print(f"{Colors.BLUE}{'='*60}{Colors.END}")
    
    if total_errors == 0 and total_warnings == 0:
        print(f"{Colors.GREEN}‚úÖ All JSON files are valid!{Colors.END}")
        print(f"{Colors.GREEN}   Safe to proceed with Kaggle training.{Colors.END}")
        return 0
    elif total_errors == 0:
        print(f"{Colors.YELLOW}‚ö†Ô∏è  {total_warnings} warning(s) (missing files - will be generated){Colors.END}")
        print(f"{Colors.GREEN}   No structural errors found. Safe to proceed.{Colors.END}")
        return 0
    else:
        print(f"{Colors.RED}‚ùå Found {total_errors} error(s) and {total_warnings} warning(s){Colors.END}")
        print(f"{Colors.RED}   Please fix errors before running Kaggle training!{Colors.END}")
        return 1

if __name__ == "__main__":
    sys.exit(main())
